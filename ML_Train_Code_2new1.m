% Written by Mmt Dec 2023 at ITU . It uses the preinstalled digitTrain4Darray set ! 
% It creates a linear DAG CNN for 15 layers. 
% uses the derivers and their names as labels !!! As an Alternative way to hold data !
% ~/matlab/PHY441E/MLpart/DigitDataset/0  1  2  3  4  5  6  7  8  9 <- Directories 

imds=imageDatastore('DigitDataset','IncludeSubfolders',true, 'LabelSource','foldernames');
[imdsTrain,imdsValidation] = splitEachLabel(imds,0.8);
                    %imdsTrain : 8000 files and imdsValidation : 2000 files we found more data !!!

numClasses = numel(categories(imdsTrain.Labels));  % 10 items mean 10 digits 0..9 

imageAugmenter = imageDataAugmenter('RandRotation',[-20,20], 'RandXTranslation',[-3 3], ...
    'RandYTranslation',[-3 3]);
    
    %'RandXReflection',true, 'RandXScale',[0.9 1.1],'RandYScale',[0.9 1.1]);

imageSize=size(imread(imdsTrain.Files{1})); %imageSize = [28 28 1]; % gives out [28 28]

%augimds = augmentedImageDatastore(imageSize,resimtrain,labeltrain,'DataAugmentation',imageAugmenter);
augimdsTrain = augmentedImageDatastore(imageSize,imdsTrain, 'DataAugmentation',imageAugmenter);
augimdsValidation = augmentedImageDatastore(imageSize,imdsValidation);
% here image train tethered label train is done in imageDatastore structure....

layers = [imageInputLayer(imageSize)
          convolution2dLayer(3,8,'Padding','same')
          batchNormalizationLayer
          reluLayer   
          maxPooling2dLayer(2,'Stride',2)
          convolution2dLayer(3,16,'Padding','same')
          batchNormalizationLayer
          reluLayer   
          maxPooling2dLayer(2,'Stride',2)
          convolution2dLayer(3,32,'Padding','same')
          batchNormalizationLayer
          reluLayer   
          fullyConnectedLayer(10)
          softmaxLayer
          classificationLayer];

mBS=15;
valFrequency = floor(numel(augimdsTrain.Files)/mBS);
options = trainingOptions('sgdm', ...
    'ExecutionEnvironment','multi-gpu',...
    'MiniBatchSize',mBS, ...
    'MaxEpochs',16, ...
    'InitialLearnRate',1e-2, ...   
    'Shuffle','every-epoch', ...
    'ValidationData',augimdsValidation, ...
    'ValidationFrequency',valFrequency, ...
    'Verbose',false, ...
    'Plots','training-progress',...
    'LearnRateSchedule','piecewise' ); 
%OR %    
options = trainingOptions('adam', ...
    'ExecutionEnvironment','multi-gpu',...
    'MiniBatchSize',mBS, ...
    'MaxEpochs',16, ...
    'InitialLearnRate',1e-2, ...   
    'Shuffle','every-epoch', ...
    'ValidationData',augimdsValidation, ...
    'ValidationFrequency',valFrequency, ...
    'Verbose',false, ...
    'Plots','training-progress',...
    'LearnRateSchedule','piecewise',...
    'OutputNetwork','best-validation-loss');    
    
    
% LearningRate 0.01 works better than 0.1 or 0.003 ;    
%opts = trainingOptions("sgdm","ExecutionEnvironment","gpu","MaxEpochs",15, "Shuffle","every-%epoch", ...
%                       "Plots","training-progress","Verbose",false, ...
%                        "ValidationData",{resimkontrol,labelkontrol});
%%%%% here again ValidationData is done imageDatastore property !!!!!!! %%%%%%%%%%%
  
%opts = trainingOptions("sgdm","ExecutionEnvironment","auto","MaxEpochs",15, "Shuffle",...
%                        "every-epoch", ...
%                       "Plots","training-progress","Verbose",false, ...
%                        "ValidationData",{resimkontrol,labelkontrol});

%opts = trainingOptions("sgdm","ExecutionEnvironment","cpu","MaxEpochs",15, "Shuffle",...
%                        "every-epoch", ...
%                       "Plots","training-progress","Verbose",false, ...
%                        "ValidationData",{resimkontrol,labelkontrol});

%opts = trainingOptions("sgdm","ExecutionEnvironment","parallel","MaxEpochs",15, "Shuffle",...
%                        "every-epoch", ...
%                         "Plots","training-progress","Verbose",false, ...
%                        "ValidationData",{resimkontrol,labelkontrol});

% delete(gcp('nocreate')); % To TURN OFF Multiple CPU option
% now we did not change anyting though ;;; 
%opts.ValidationData{1}(:,:,:,1)-XValidation(:,:,:,1) 

% gives only 0 's ... So they are same matrices. 
  
                       
%net = trainNetwork(augimds,layers,opts);      
net=trainNetwork(augimdsTrain,layers,options); 

%parpool;
%tic;
%parfor i=1:gpuDeviceCount("available")
%net = trainNetwork(augimds,layers,opts);
%end
%toc
%augimdsValidation = augmentedImageDatastore(imageSize,resimkontrol);
%classify(net,resimkontrol(:,:,3)) % now we can use the net to define what have in.
[Predictions, Probabilities]= classify(net,augimdsValidation);
accuracy = mean(Predictions == imdsValidation.Labels); 

